"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1993],{4137:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>_});var a=t(7294);function s(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){s(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,a,s=function(e,n){if(null==e)return{};var t,a,s={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(s[t]=e[t]);return s}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}var l=a.createContext({}),p=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},c=function(e){var n=p(e.components);return a.createElement(l.Provider,{value:n},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,s=e.mdxType,r=e.originalType,l=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),d=p(t),u=s,_=d["".concat(l,".").concat(u)]||d[u]||m[u]||r;return t?a.createElement(_,o(o({ref:n},c),{},{components:t})):a.createElement(_,o({ref:n},c))}));function _(e,n){var t=arguments,s=n&&n.mdxType;if("string"==typeof e||s){var r=t.length,o=new Array(r);o[0]=u;var i={};for(var l in n)hasOwnProperty.call(n,l)&&(i[l]=n[l]);i.originalType=e,i[d]="string"==typeof e?e:s,o[1]=i;for(var p=2;p<r;p++)o[p]=t[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},1628:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>p});var a=t(7462),s=(t(7294),t(4137));const r={id:"solution-deploy",sidebar_position:1,title:"Deploy"},o="Deploy",i={unversionedId:"Create/solution-deploy",id:"Create/solution-deploy",title:"Deploy",description:"Manually deploy to learn. Automatically deploy to scale.",source:"@site/docs/3-Create/Deploy.md",sourceDirName:"3-Create",slug:"/Create/solution-deploy",permalink:"/solution-filenet-aws/Create/solution-deploy",draft:!1,editUrl:"https://github.com/ibm-client-engineering/solution-filenet-aws/tree/main/packages/create-docusaurus/templates/shared/docs/3-Create/Deploy.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"solution-deploy",sidebar_position:1,title:"Deploy"},sidebar:"tutorialSidebar",previous:{title:"Create",permalink:"/solution-filenet-aws/category/create"},next:{title:"Validate",permalink:"/solution-filenet-aws/Create/solution-validate"}},l={},p=[{value:"Deploy OpenLDAP",id:"deploy-openldap",level:2},{value:"Deploy Postgres",id:"deploy-postgres",level:2},{value:"Create databases",id:"create-databases",level:3},{value:"Deploy Operator",id:"deploy-operator",level:2},{value:"Scripted Operator deployment",id:"scripted-operator-deployment",level:3},{value:"Manual Operator deployment",id:"manual-operator-deployment",level:3},{value:"Create the <code>ibm-fncm-secret</code>",id:"create-the-ibm-fncm-secret",level:3},{value:"Create the <code>ibm-ban-secret</code> for Navigator",id:"create-the-ibm-ban-secret-for-navigator",level:3},{value:"Deploying CR",id:"deploying-cr",level:2}],c={toc:p},d="wrapper";function m(e){let{components:n,...t}=e;return(0,s.kt)(d,(0,a.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"deploy"},"Deploy"),(0,s.kt)("admonition",{type:"info"},(0,s.kt)("p",{parentName:"admonition"},(0,s.kt)("strong",{parentName:"p"}," Manually deploy to learn. Automatically deploy to scale.")),(0,s.kt)("p",{parentName:"admonition"},"This section goes through the deployment of FileNet on AWS EKS ",(0,s.kt)("em",{parentName:"p"},"step-by-step"))),(0,s.kt)("h2",{id:"deploy-openldap"},"Deploy OpenLDAP"),(0,s.kt)("p",null,"Let's create a namespace for openldap (This is optional. For the rest of this, we'll just stick openldap into our filenet namespace)"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"kubectl create namespace filenet-openldap\nkubectl label namespace filenet-openldap app=filenet-openldap\n")),(0,s.kt)("p",null,"Set our context to the new namespace (only if you created a separate namespace to run openldap in)"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"kubectl config set-context --current --namespace=filenet-openldap\n")),(0,s.kt)("p",null,"Let's create some configmaps for the ldap service"),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"openldap-schemas-configmap.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"showLineNumbers",showLineNumbers:!0},"kind: ConfigMap\napiVersion: v1\nmetadata:\n  name: openldap-customschema\n  labels:\n    app: filenet-openldap\ndata:\n  custom.ldif: |-\n    dn: cn=sds,cn=schema,cn=config\n    objectClass: olcSchemaConfig\n    cn: sds\n    olcAttributeTypes: {0}( 1.3.6.1.4.1.42.2.27.4.1.6 NAME 'ibm-entryuuid' DESC \n      'Uniquely identifies a directory entry throughout its life.' EQUALITY caseIgnoreMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.15 SINGLE-VALUE )\n    olcObjectClasses: {0}( 1.3.6.1.4.1.42.2.27.4.2.1 NAME 'sds' DESC 'sds' SUP top AUXILIARY MUST ( cn $ ibm-entryuuid ) )\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"kubectl apply -f openldap-schemas-configmap.yaml\n")),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"openldap-ldif-configmap.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},"kind: ConfigMap\napiVersion: v1\nmetadata:\n  name: openldap-customldif\n  labels:\n    app: filenet-openldap\ndata:\n  01-default-users.ldif: |-\n    # cp.internal\n    dn: dc=filenet,dc=internal\n    objectClass: top\n    objectClass: dcObject\n    objectClass: organization\n    o: filenet.internal\n    dc: filenet\n\n    # Units\n    dn: ou=Users,dc=filenet,dc=internal\n    objectClass: organizationalUnit\n    ou: Users\n\n    dn: ou=Groups,dc=filenet,dc=internal\n    objectClass: organizationalUnit\n    ou: Groups\n\n    # Users\n    dn: uid=cpadmin,ou=Users,dc=filenet,dc=internal\n    objectClass: inetOrgPerson\n    objectClass: top\n    objectClass: sds\n    cn: cpadmin\n    sn: cpadmin\n    uid: cpadmin\n    mail: cpadmin@cp.internal\n    userpassword: Password\n    employeeType: admin\n    ibm-entryuuid: e6c41859-ced3-4772-bfa3-6ebbc58ec78a\n\n    dn: uid=cpuser,ou=Users,dc=filenet,dc=internal\n    objectClass: inetOrgPerson\n    objectClass: top\n    objectClass: sds\n    cn: cpuser\n    sn: cpuser\n    uid: cpuser\n    mail: cpuser@cp.internal\n    userpassword: Password\n    ibm-entryuuid: 30183bb0-1012-4d23-8ae2-f94816b91a75\n\n    # Groups\n    dn: cn=cpadmins,ou=Groups,dc=filenet,dc=internal\n    objectClass: groupOfNames\n    objectClass: top\n    objectClass: sds\n    cn: cpadmins\n    ibm-entryuuid: 4196cb9e-1ed7-4c02-bb0d-792cb7bfa768\n    member: uid=cpadmin,ou=Users,dc=filenet,dc=internal\n\n    dn: cn=cpusers,ou=Groups,dc=filenet,dc=internal\n    objectClass: groupOfNames\n    objectClass: top\n    objectClass: sds\n    cn: cpusers\n    ibm-entryuuid: fc4ded27-8c6a-4a8c-ad9e-7be65369758c\n    member: uid=cpadmin,ou=Users,dc=filenet,dc=internal\n    member: uid=cpuser,ou=Users,dc=filenet,dc=internal\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"kubectl apply -f openldap-ldif-configmap.yaml\n")),(0,s.kt)("p",null,"Create an env configmap"),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"openldap-env-configmap.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},"kind: ConfigMap\napiVersion: v1\nmetadata:\n  name: openldap-env\n  labels:\n    app: filenet-openldap\ndata:\n  BITNAMI_DEBUG: 'true'\n  LDAP_ORGANISATION: filnet.internal\n  LDAP_ROOT: 'dc=filenet,dc=internal'\n  LDAP_DOMAIN: filenet.internal\n  LDAP_CUSTOM_LDIF_DIR: /ldifs\n  LDAP_ADMIN_USERNAME: admin\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"kubectl apply -f openldap-env-configmap.yaml\n")),(0,s.kt)("p",null,"And finally create a secret for the LDAP_ADMIN_PASSWORD. In this example we are setting the default admin password to ",(0,s.kt)("inlineCode",{parentName:"p"},"p@ssw0rd")),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"openldap-admin-secret.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"kind: Secret\napiVersion: v1\nmetadata:\n  name: openldap\n  labels:\n    app: filenet-openldap\nstringData:\n  LDAP_ADMIN_PASSWORD: p@ssw0rd\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"kubectl apply -f openldap-admin-secret.yaml\n")),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"ldap_secrets.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"showLineNumbers",showLineNumbers:!0},'kind: Secret\napiVersion: v1\nmetadata:\n  name: ldap-bind-secret\n  namespace: filenet\n  labels:\n    app: filenet-openldap\nstringData:\n  ldapUsername: "cn=admin,dc=filenet,dc=internal"\n  ldapPassword: p@ssw0rd\n  externalLdapUsername: "cn=admin,dc=filenet,dc=internal"\n  externalLdapPassword: p@ssw0rd\n')),(0,s.kt)("p",null,"Apply it to the cluster"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"kubectl apply -f ldap_secrets.yaml\n")),(0,s.kt)("p",null,"Now let's create a deployment."),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"openldap-deploy.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},"kind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: openldap-deploy\n  labels:\n    app: filenet-openldap\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: filenet-openldap\n  template:\n    metadata:\n      labels:\n        app: filenet-openldap\n    spec:\n      containers:\n        - name: openldap\n          resources:\n            requests:\n              cpu: 100m\n              memory: 256Mi\n            limits:\n              cpu: 500m\n              memory: 512Mi\n          startupProbe:\n            tcpSocket:\n              port: ldap-port\n            timeoutSeconds: 1\n            periodSeconds: 10\n            successThreshold: 1\n            failureThreshold: 30\n          readinessProbe:\n            tcpSocket:\n              port: ldap-port\n            initialDelaySeconds: 60\n            timeoutSeconds: 1\n            periodSeconds: 10\n            successThreshold: 1\n            failureThreshold: 10\n          livenessProbe:\n            tcpSocket:\n              port: ldap-port\n            initialDelaySeconds: 60\n            timeoutSeconds: 1\n            periodSeconds: 10\n            successThreshold: 1\n            failureThreshold: 10\n          terminationMessagePath: /dev/termination-log\n          ports:\n            - name: ldap-port\n              containerPort: 1389\n              protocol: TCP\n          image: 'bitnami/openldap:latest'\n          imagePullPolicy: Always\n          securityContext:\n            capabilities:\n              drop:\n                - ALL\n            runAsNonRoot: true\n            allowPrivilegeEscalation: false\n            seccompProfile:\n              type: RuntimeDefault\n          volumeMounts:\n            - name: custom-schema-files\n              mountPath: /schemas/\n            - name: custom-ldif-files\n              mountPath: /ldifs/\n          terminationMessagePolicy: File\n          envFrom:\n            - configMapRef:\n                name: openldap-env\n            - secretRef:\n                name: openldap\n      # If you have a custom pull secret and have staged the image somewhere\n#      imagePullSecrets:\n#        - name: <CUSTOM PULL SECRET>\n      #\n      volumes:\n        - name: custom-schema-files\n          configMap:\n            name: openldap-customschema\n            defaultMode: 420\n        - name: custom-ldif-files\n          configMap:\n            name: openldap-customldif\n            defaultMode: 420\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"kubectl apply -f openldap-deploy.yaml\n")),(0,s.kt)("p",null,"Create a service for openldap"),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"openldap-service.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},"kind: Service\napiVersion: v1\nmetadata:\n  name: openldap\n  labels:\n    app: filenet-openldap\nspec:\n  ports:\n    - name: ldap-port\n      protocol: TCP\n      port: 389\n      targetPort: ldap-port\n  type: NodePort\n  selector:\n    app: filenet-openldap\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"kubectl apply -f openldap-service.yaml\n")),(0,s.kt)("p",null,"Verifying on the openldap pod"),(0,s.kt)("p",null,"Retrieve the ldap pod name"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pods\nNAME                               READY   STATUS    RESTARTS   AGE\nopenldap-deploy-67888c7868-9ncrc   1/1     Running   0          5m15s\n")),(0,s.kt)("p",null,"Run an ldapsearch in the pod"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl exec -it openldap-deploy-67888c7868-9ncrc -- ldapsearch -x -b \"dc=filenet,dc=internal\" -H ldap://localhost:1389 -D 'cn=admin,dc=filenet,dc=internal' -w p@ssw0rd\n")),(0,s.kt)("p",null,"It should return a list of the users and groups configured in the config map."),(0,s.kt)("admonition",{type:"info"},(0,s.kt)("p",{parentName:"admonition"},"If users are not being created in the ldap instance, you can verify the ldifs are valid with the following command in the ldap pod:"),(0,s.kt)("pre",{parentName:"admonition"},(0,s.kt)("code",{parentName:"pre"},'ldapadd -x -D "cn=admin,dc=filenet,dc=internal" -w p@ssw0rd -H ldapi:/// -f /ldifs/01-default-users.ldif\n'))),(0,s.kt)("h2",{id:"deploy-postgres"},"Deploy Postgres"),(0,s.kt)("p",null,"Let's create a configmap for the PGSQL database to use:"),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"postgres_configmap.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},"kind: ConfigMap\napiVersion: v1\nmetadata:\n  name: postgres-config\n  labels:\n    app: postgres\ndata:\n  POSTGRES_DB: defaultdb\n  POSTGRES_USER: admin\n  POSTGRES_PASSWORD: p@ssw0rd\n  PGDATA: /var/lib/postgresql/data/pgdata\n")),(0,s.kt)("p",null,"Now lets create a pair of ebs storage device PVCs for the database data and tablespaces."),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"postgres-pvc.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},"kind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: postgres-data\n  namespace: filenet\n  labels:\n    app: postgres\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  storageClassName: ebs-gp3-sc\n  volumeMode: Filesystem\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: postgres-tablespaces\n  labels:\n    app: postgres\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: ebs-gp3-sc\n  volumeMode: Filesystem\n")),(0,s.kt)("p",null,"Create a deployment for postgres"),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"postgres-deploy.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres  # Sets Deployment name\n  namespace: filenet\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      securityContext:\n        runAsUser: 2000\n        runAsGroup: 2000\n        fsGroup: 65536\n      containers:\n        - name: postgres\n          image: postgres:latest # Sets Image\n          imagePullPolicy: "IfNotPresent"\n          ports:\n            - containerPort: 5432  # Exposes container port\n          envFrom:\n            - configMapRef:\n                name: postgres-config\n          volumeMounts:\n            - mountPath: /var/lib/postgresql/data\n              name: postgredb\n            - mountPath: /pgsqldata\n              name: postgres-tablespaces\n      volumes:\n        - name: postgresdb\n          persistentVolumeClaim:\n            claimName: postgres-data\n        - name: postgres-tablespaces\n          persistentVolumeClaim:\n            claimName: postgres-tablespaces\n')),(0,s.kt)("p",null,"Create the service for postgres\n",(0,s.kt)("inlineCode",{parentName:"p"},"postgres-service.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},"kind: Service\napiVersion: v1\nmetadata:\n  name: postgres\n  labels:\n    app: postgres\nspec:\n  ports:\n    - name: pgsql-port\n      protocol: TCP\n      port: 5432\n      targetPort: 5432\n  type: NodePort\n  selector:\n    app: postgres\n\n")),(0,s.kt)("p",null,"These yaml files are not set to any specific namespace, so make sure you've set your kubectl context accordingly to the namespace you want to deploy them in. As a default, we should have set our namespace context to ",(0,s.kt)("inlineCode",{parentName:"p"},"filenet"),"."),(0,s.kt)("p",null,"Now apply the above yaml files to the cluster:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f postgres_configmap.yaml\nkubectl apply -f postgres-pvc.yaml\nkubectl apply -f postgres-deploy.yaml\nkubectl apply -f postgres-service.yaml\n")),(0,s.kt)("p",null,"Verify the postgres default database we configured above is up. You can get the pod name from ",(0,s.kt)("inlineCode",{parentName:"p"},"kubectl get pods")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"kubectl exec -it postgres-POD-ID -- psql -h localhost -U admin --password -p 5432 defaultdb\n")),(0,s.kt)("h3",{id:"create-databases"},"Create databases"),(0,s.kt)("p",null,"Connect to the postgres pod"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"kubectl exec -it postgres-POD-ID -- bash\n")),(0,s.kt)("p",null,"Create the tablespace directories"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"mkdir /pgsqldata/osdb /pgsqldata/gcddb /pgsqldata/icndb\n\nchmod 700 /pgsqldata/osdb /pgsqldata/gcddb /pgsqldata/icndb\n\n")),(0,s.kt)("p",null,"Connect to the default db. Our password will be ",(0,s.kt)("inlineCode",{parentName:"p"},"p@ssw0rd"),"."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"psql -h localhost -U admin --password -p 5432 defaultdb\n")),(0,s.kt)("p",null,"Create the ",(0,s.kt)("inlineCode",{parentName:"p"},"ceuser")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"create role ceuser login password 'p@ssw0rd';\n")),(0,s.kt)("p",null,"Create the GCD database. When you run the ",(0,s.kt)("inlineCode",{parentName:"p"},"\\connect")," command, it will query you for the password. It will still be ",(0,s.kt)("inlineCode",{parentName:"p"},"p@ssw0rd"),"."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"CREATE DATABASE gcddb OWNER ceuser TEMPLATE template0 ENCODING UTF8;\nGRANT ALL ON DATABASE gcddb TO ceuser;\nREVOKE CONNECT ON DATABASE gcddb FROM public;\n\\connect gcddb\nCREATE TABLESPACE gcddb_tbs OWNER ceuser LOCATION '/pgsqldata/gcddb';\nGRANT CREATE ON TABLESPACE gcddb_tbs TO ceuser;\n")),(0,s.kt)("p",null,"Create the Object Store database. When you run the ",(0,s.kt)("inlineCode",{parentName:"p"},"\\connect")," command, it will query you for the password. It will still be ",(0,s.kt)("inlineCode",{parentName:"p"},"p@ssw0rd"),"."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"CREATE DATABASE osdb OWNER ceuser TEMPLATE template0 ENCODING UTF8 ;\nGRANT ALL ON DATABASE osdb TO ceuser;\nREVOKE CONNECT ON DATABASE osdb FROM public;\n\\connect osdb\nCREATE TABLESPACE osdb_tbs OWNER ceuser LOCATION '/pgsqldata/osdb';\nGRANT CREATE ON TABLESPACE osdb_tbs TO ceuser;\n")),(0,s.kt)("p",null,"Create the ICN database. When you run the ",(0,s.kt)("inlineCode",{parentName:"p"},"\\connect")," command, it will query you for the password. It will still be ",(0,s.kt)("inlineCode",{parentName:"p"},"p@ssw0rd"),"."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"CREATE DATABASE icndb OWNER ceuser TEMPLATE template0 ENCODING UTF8;\nGRANT ALL ON DATABASE icndb TO ceuser;\nREVOKE CONNECT ON DATABASE gcddb FROM public;\n\\connect icndb\nCREATE TABLESPACE icndb_tbs OWNER ceuser LOCATION '/pgsqldata/icndb';\nGRANT CREATE ON TABLESPACE icndb_tbs TO ceuser;\n")),(0,s.kt)("h2",{id:"deploy-operator"},"Deploy Operator"),(0,s.kt)("p",null,"Download the IBM Case file for FileNet Content Manager. As of this writing it is ",(0,s.kt)("strong",{parentName:"p"},"v1.6.2"),". You can check for newer versions by going ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/IBM/cloud-pak/tree/master/repo/case/ibm-cp-fncm-case"},"here")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"wget https://github.com/IBM/cloud-pak/raw/master/repo/case/ibm-cp-fncm-case/1.6.2/ibm-cp-fncm-case-1.6.2.tgz\n")),(0,s.kt)("p",null,"Extract the case file"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"tar zxvf ibm-cp-fncm-case-1.6.2.tgz\n")),(0,s.kt)("p",null,"Change into the operator directory and extract the container samples file"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"cd ibm-cp-fncm-case/inventory/fncmOperator/files/deploy/crs/\n\ntar xvf container-samples-5.5.10.tar\n")),(0,s.kt)("h3",{id:"scripted-operator-deployment"},"Scripted Operator deployment"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"cd container-samples/scripts\n")),(0,s.kt)("p",null,"Create ",(0,s.kt)("inlineCode",{parentName:"p"},"filenetvars.sh")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},'#!/bin/bash\n# set -x\n###############################################################################\n#\n# Licensed Materials - Property of IBM\n#\n# (C) Copyright IBM Corp. 2021. All Rights Reserved.\n#\n# US Government Users Restricted Rights - Use, duplication or\n# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n#\n###############################################################################\n\nexport FNCM_PLATFORM="other"\nexport FNCM_NAMESPACE="filenet"\nexport FNCM_LICENSE_ACCEPT="Accept"\nexport FNCM_STORAGE_CLASS="efs-sc"\nexport FNCM_ENTITLEMENT_KEY="<ENTITLEMENT_KEY>"\n')),(0,s.kt)("p",null,"You can retrieve your entitlement key from this URL:\n",(0,s.kt)("a",{parentName:"p",href:"https://myibm.ibm.com/products-services/containerlibrary"},"https://myibm.ibm.com/products-services/containerlibrary")),(0,s.kt)("p",null,"Source the ",(0,s.kt)("inlineCode",{parentName:"p"},"filenetvars.sh")," file and then run the installation script from that directory:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"source ./filenetvars.sh\n./deployOperator.sh\n")),(0,s.kt)("h3",{id:"manual-operator-deployment"},"Manual Operator deployment"),(0,s.kt)("p",null,"If you cannot run the deployment script, follow these steps to deploy the operator manually."),(0,s.kt)("p",null,"From the ",(0,s.kt)("inlineCode",{parentName:"p"},"container-samples")," directory:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},"cd ibm-cp-fncm-case/inventory/fncmOperator/files/deploy/crs/container-samples\nkubectl apply -f ./descriptors/fncm_v1_fncm_crd.yaml\nkubectl apply -f ./descriptors/service_account.yaml\nkubectl apply -f ./descriptors/role.yaml\nkubectl apply -f ./descriptors/role_binding.yaml\nkubectl apply -f ./descriptors/operator.yaml\n")),(0,s.kt)("h3",{id:"create-the-ibm-fncm-secret"},"Create the ",(0,s.kt)("inlineCode",{parentName:"h3"},"ibm-fncm-secret")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},'kubectl create secret generic ibm-fncm-secret \\\n--from-literal=gcdDBUsername="ceuser" \\\n--from-literal=gcdDBPassword="p@ssw0rd" \\\n--from-literal=osDBUsername="ceuser" \\\n--from-literal=osDBPassword="p@ssw0rd" \\\n--from-literal=appLoginUsername="cpadmin" \\\n--from-literal=appLoginPassword="Password" \\\n--from-literal=keystorePassword="p@ssw0rd" \\\n--from-literal=ltpaPassword="p@ssw0rd"\n')),(0,s.kt)("h3",{id:"create-the-ibm-ban-secret-for-navigator"},"Create the ",(0,s.kt)("inlineCode",{parentName:"h3"},"ibm-ban-secret")," for Navigator"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-tsx"},'kubectl create secret generic ibm-ban-secret \\\n  --from-literal=navigatorDBUsername="ceuser" \\\n  --from-literal=navigatorDBPassword="p@ssw0rd" \\\n  --from-literal=keystorePassword="p@ssw0rd" \\\n  --from-literal=ltpaPassword="p@ssw0rd" \\\n  --from-literal=appLoginUsername="cpadmin" \\\n  --from-literal=appLoginPassword="Password" \\\n  --from-literal=jMailUsername="mailadmin" \\\n  --from-literal=jMailPassword="{xor}GDoxNiosbg=="\n')),(0,s.kt)("p",null,"Create a secret in the filenet namespace for the ldap-bind secret"),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"ldap_secrets.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},'kind: Secret\napiVersion: v1\nmetadata:\n  name: ldap-bind-secret\n  namespace: filenet\n  labels:\n    app: filenet-openldap\nstringData:\n  ldapUsername: "cn=admin,dc=filenet,dc=internal"\n  ldapPassword: p@ssw0rd\n  externalLdapUsername: "cn=admin,dc=filenet,dc=internal"\n  externalLdapPassword: p@ssw0rd\n')),(0,s.kt)("p",null,"Apply it to the cluster"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f ldap_secrets.yaml\n")),(0,s.kt)("h2",{id:"deploying-cr"},"Deploying CR"),(0,s.kt)("p",null,"Here is our example CR. Use it as reference. It would be applied with the following command to the cluster. Make sure you're in your correct namespace or have your namespace context set."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f ibm_fncm_cr_production_abrv.yaml\n")),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"ibm_fncm_cr_production_abrv.yaml")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: fncm.ibm.com/v1\nkind: FNCMCluster\nmetadata:\n  name: fncmdeploy\n  labels:\n    app.kubernetes.io/instance: ibm-fncm\n    app.kubernetes.io/managed-by: ibm-fncm\n    app.kubernetes.io/name: ibm-fncm\n    release: 5.5.10\nspec:\n  appVersion: 22.0.2\n  var_setlog_true: false\n  var_navigator_no_log: false\n  var_fncm_no_log: false\n  license:\n    accept: true\n  content_optional_components:\n    cmis: true\n    css: true\n    es: false\n    tm: true\n\n  shared_configuration:\n    sc_service_type: NodePort\n    sc_ingress_enable: true\n# Set the sc_ingress_hostname_alias only if you have an FQDN already.\n    sc_ingress_hostname_alias: "filenet.filenet-east.frwd-labs.link"\n# Set the tls secret name if you have a pre-existing cert already in the cluster or you are using cert-manager.\n    sc_ingress_tls_secret_name: "letsencrypt-filenet-east-prod-cluster-cert"\n    sc_ingress_annotations:\n      - nginx.ingress.kubernetes.io/affinity: cookie\n# Set cert-manager.io/issuer if you\'ve configured cert-manager in your cluster and have set a namespace scoped issuer for it. If you created a cluster-scoped issuer, this would be cert-manager.io/cluster-issuer\n      - cert-manager.io/issuer: "letsencrypt-prod"\n      - nginx.ingress.kubernetes.io/force-ssl-redirect: "true"\n      - nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"\n      - nginx.ingress.kubernetes.io/secure-backends: "true"\n      - nginx.ingress.kubernetes.io/session-cookie-name: route\n      - nginx.ingress.kubernetes.io/session-cookie-hash: sha1\n      - kubernetes.io/ingress.class: nginx\n    no_log: false\n    sc_deployment_context: FNCM\n    image_pull_secrets:\n    - ibm-entitlement-key\n    sc_image_repository: cp.icr.io\n    root_ca_secret: fncm-root-ca\n    sc_deployment_patterns: content\n    sc_deployment_type: production\n    sc_fncm_license_model: "FNCM.PVUNonProd"\n    sc_deployment_profile_size: "medium"\n    sc_run_as_user:\n    sc_deployment_platform: "other"\n    # If you are using an FQDN, set it here for sc_deployment_hostname_suffix. Else comment this.\n    sc_deployment_hostname_suffix: "filenet.filenet-east.frwd-labs.link" \n    trusted_certificate_list: []\n    sc_content_initialization:\n      cpe: true\n      css: false\n      ban: false\n    sc_content_verification: false\n    storage_configuration:\n      sc_slow_file_storage_classname: "efs-sc"\n      sc_medium_file_storage_classname: "efs-sc"\n      sc_fast_file_storage_classname: "efs-sc"\n\n  ldap_configuration:\n  # Our example is actually using OpenLDAP, but this seems to be the only way to get it to work\n    lc_selected_ldap_type: "IBM Security Directory Server"\n    lc_ldap_precheck: true\n  # Should be the cluster-ip of the ldap service\n    lc_ldap_server: "10.100.217.46"\n    lc_ldap_port: "389"\n    lc_bind_secret: ldap-bind-secret\n    lc_ldap_base_dn: "dc=filenet,dc=internal"\n    lc_ldap_ssl_enabled: false\n    lc_ldap_ssl_secret_name: "ldap"\n    #lc_ldap_user_name_attribute: "*:uid"\n    lc_ldap_user_name_attribute: "*:cn"\n    lc_ldap_user_display_name_attr: "cn"\n    lc_ldap_group_base_dn: "ou=Groups,dc=filenet,dc=internal"\n    lc_ldap_group_name_attribute: "*:cn"\n    lc_ldap_group_display_name_attr: "cn"\n    lc_ldap_group_membership_search_filter: "(|(&(objectclass=groupofnames)(member={0}))(&(objectclass=groupofuniquenames)(uniquemember={0})))"\n    lc_ldap_group_member_id_map: "groupofnames:member"\n    tds:\n      lc_user_filter: "(&(cn=%v)(objectclass=inetOrgPerson))"\n      lc_group_filter: "(&(cn=%v)(|(objectclass=groupOfNames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"\n\n  datasource_configuration:\n    dc_ssl_enabled: false\n    database_precheck: true\n    dc_gcd_datasource:\n      dc_database_type: "postgresql"\n      dc_common_gcd_datasource_name: "FNGCDDS"\n      dc_common_gcd_xa_datasource_name: "FNGCDDSXA"\n  # Should be the cluster-ip of your postgresql service if running postgres in a pod, or the ip of your RDS instance\n      database_servername: "10.100.80.28"\n      database_name: "gcddb"\n      database_port: "5432"\n      database_ssl_secret_name: "<Required>"\n      dc_oracle_gcd_jdbc_url: "<Required>"\n      dc_hadr_validation_timeout: 15\n      dc_hadr_standby_servername: "<Required>"\n      dc_hadr_standby_port: "<Required>"\n      dc_hadr_retry_interval_for_client_reroute: 15\n      dc_hadr_max_retries_for_client_reroute: 3\n    dc_os_datasources:\n    - dc_database_type: "postgresql"\n      dc_os_label: "os"\n      dc_common_os_datasource_name: "FNOS1DS"\n      dc_common_os_xa_datasource_name: "FNOS1DSXA"\n  # Should be the cluster-ip of your postgresql service if running postgres in a pod, or the ip of your RDS instance\n      database_servername: "10.100.80.28"\n      database_name: "osdb"\n      database_port: "5432"\n      database_ssl_secret_name: "<Required>"\n      dc_oracle_os_jdbc_url: "<Required>"\n      dc_hadr_validation_timeout: 15\n      dc_hadr_standby_servername: "<Required>"\n      dc_hadr_standby_port: "<Required>"\n      dc_hadr_retry_interval_for_client_reroute: 15\n      dc_hadr_max_retries_for_client_reroute: 3\n    dc_icn_datasource:\n      dc_database_type: "postgresql"\n      dc_common_icn_datasource_name: "ECMClientDS"\n  # Should be the cluster-ip of your postgresql service if running postgres in a pod, or the ip of your RDS instance\n      database_servername: "10.100.80.28"\n      database_port: "5432"\n      database_name: "icndb"\n      database_ssl_secret_name: "<Required>"\n      dc_oracle_icn_jdbc_url: "<Required>"\n      dc_hadr_validation_timeout: 15\n      dc_hadr_standby_servername: "<Required>"\n      dc_hadr_standby_port: "<Required>"\n      dc_hadr_retry_interval_for_client_reroute: 15\n      dc_hadr_max_retries_for_client_reroute: 3\n  initialize_configuration:\n    ic_ldap_creation:\n      ic_ldap_admin_user_name:\n        - "cpadmin" # user name for P8 domain admin, for example, "CEAdmin".  This parameter accepts a list of values.\n      ic_ldap_admins_groups_name:\n        - "cpadmins" # group name for P8 domain admin, for example, "P8Administrators".  This parameter accepts a list of values.\n      ic_ldap_name: ldap\n    ic_domain_creation:\n      domain_name: "P8DOMAIN"\n      encryption_key: "128"\n    ic_obj_store_creation:\n      object_stores:\n        - oc_cpe_obj_store_display_name: "OS01" # Required display name of the object store, for example, "OS01"\n          oc_cpe_obj_store_symb_name: "OS01" # Required symbolic name of the object store, for example, "OS01"\n          oc_cpe_obj_store_conn:\n            name: "OS01_dbconnection"\n            dc_os_datasource_name: "FNOS1DS" # This value must match with the non-XA datasource name in the "datasource_configuration" above.\n            dc_os_xa_datasource_name: "FNOS1DSXA" # This value must match with the XA datasource name in the "datasource_configuration" above.\n          oc_cpe_obj_store_admin_user_groups:\n            - "cpadmins" # user name and group name for object store admin, for example, "CEAdmin" or "P8Administrators".  This parameter accepts a list of values.\n  ecm_configuration:\n    fncm_secret_name: ibm-fncm-secret\n    route_ingress_annotations:\n    disable_fips: true\n    node_affinity:\n      custom_node_selector_match_expression: [ ]\n    custom_annotations: { }\n    custom_labels: { }\n\n    cpe:\n      arch:\n        amd64: "3 - Most preferred"\n      replica_count: 2\n      image:\n        ## The default repository is the IBM Entitled Registry.\n        repository: cp.icr.io/cp/cp4a/fncm/cpe\n        tag: ga-5510-p8cpe-if001\n        pull_policy: IfNotPresent\n      log:\n       format: json\n      resources:\n        requests:\n          cpu: "500m"\n          memory: "512Mi"\n          ephemeral_storage: "4Gi"\n        limits:\n          cpu: "1"\n          memory: "3072Mi"\n          ephemeral_storage: "4Gi"\n      auto_scaling:\n        enabled: false\n        max_replicas: "<Required>"\n        min_replicas: "<Required>"\n        target_cpu_utilization_percentage: "<Required>"\n      cpe_production_setting:\n        time_zone: Etc/UTC\n        jvm_initial_heap_percentage: 18\n        jvm_max_heap_percentage: 33\n        jvm_customize_options:\n        gcd_jndi_name: FNGCDDS\n        gcd_jndixa_name: FNGCDDSXA\n        # The license must be set to "accept" in order for the component to install.  This is the default value.\n        license: accept\n      monitor_enabled: false\n      logging_enabled: false\n      collectd_enable_plugin_write_graphite: false\n      datavolume:\n        existing_pvc_for_cpe_cfgstore: \n          name: "cpe-cfgstore"\n          size: 1Gi\n        existing_pvc_for_cpe_logstore: \n          name: "cpe-logstore"\n          size: 1Gi\n        existing_pvc_for_cpe_filestore: \n          name: "cpe-filestore"\n          size: 1Gi\n        existing_pvc_for_cpe_icmrulestore: \n          name: "cpe-icmrulesstore"\n          size: 1Gi\n        existing_pvc_for_cpe_textextstore: \n          name: "cpe-textextstore"\n          size: 1Gi\n        existing_pvc_for_cpe_bootstrapstore: \n          name: "cpe-bootstrapstore"\n          size: 1Gi\n        existing_pvc_for_cpe_fnlogstore: \n          name: "cpe-fnlogstore"\n          size: 1Gi\n      probe:\n        startup:\n          initial_delay_seconds: 120\n          period_seconds: 30\n          timeout_seconds: 10\n          failure_threshold: 16\n        readiness:\n          period_seconds: 30\n          timeout_seconds: 10\n          failure_threshold: 6\n        liveness:\n          period_seconds: 30\n          timeout_seconds: 5\n          failure_threshold: 6\n      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.\n      image_pull_secrets:\n        name: "ibm-entitlement-key"\n\n    css:\n      arch:\n        amd64: "3 - Most preferred"\n      replica_count: 2\n      image:\n        ## The default repository is the IBM Entitled Registry.\n        repository: cp.icr.io/cp/cp4a/fncm/css\n        tag: ga-5510-p8css-if001\n        pull_policy: IfNotPresent\n      log:\n        format: json\n      resources:\n        requests:\n          cpu: "500m"\n          memory: "512Mi"\n          ephemeral_storage: "500Mi"\n        limits:\n          cpu: "1"\n          memory: "4096Mi"\n          ephemeral_storage: "1.5Gi"\n      css_production_setting:\n        jvm_max_heap_percentage: 50\n        license: accept\n        icc:\n          icc_enabled: false\n          icc_secret_name: "ibm-icc-secret"\n          p8domain_name: "P8DOMAIN"\n          secret_masterkey_name: "icc-masterkey-txt"\n      monitor_enabled: false\n      logging_enabled: false\n      collectd_enable_plugin_write_graphite: false\n      datavolume:\n        existing_pvc_for_css_cfgstore: \n          name: "css-cfgstore"\n          size: 1Gi\n        existing_pvc_for_css_logstore: \n          name: "css-logstore"\n          size: 1Gi\n        existing_pvc_for_css_tmpstore: \n          name: "css-tempstore"\n          size: 1Gi\n        existing_pvc_for_index: \n          name: "css-indexstore"\n          size: 1Gi\n        existing_pvc_for_css_customstore: \n          name: "css-customstore"\n          size: 1Gi\n      probe:\n        startup:\n          initial_delay_seconds: 60\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        readiness:\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        liveness:\n          period_seconds: 10\n          timeout_seconds: 5\n          failure_threshold: 6\n      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.\n      image_pull_secrets:\n        name: "ibm-entitlement-key"\n\n    cmis:\n      arch:\n        amd64: "3 - Most preferred"\n      replica_count: 2\n      image:\n        ## The default repository is the IBM Entitled Registry.\n        repository: cp.icr.io/cp/cp4a/fncm/cmis\n        tag: ga-307-cmis-la103\n        pull_policy: IfNotPresent\n      log:\n        format: json\n      resources:\n        requests:\n          cpu: "500m"\n          memory: "256Mi"\n          ephemeral_storage: "1Gi"\n        limits:\n          cpu: "1"\n          memory: "1536Mi"\n          ephemeral_storage: "1Gi"\n      auto_scaling:\n        enabled: false\n        max_replicas: "<Required>"\n        min_replicas: "<Required>"\n        target_cpu_utilization_percentage: "<Required>"\n      cmis_production_setting:\n        cpe_url:\n        time_zone: Etc/UTC\n        jvm_initial_heap_percentage: 40\n        jvm_max_heap_percentage: 66\n        jvm_customize_options:\n        ws_security_enabled: false\n        checkout_copycontent: true\n        default_maxitems: 25\n        cvl_cache: true\n        secure_metadata_cache: false\n        filter_hidden_properties: true\n        querytime_limit: 180\n        resumable_queries_forrest: true\n        escape_unsafe_string_characters: false\n        max_soap_size: 180\n        print_pull_stacktrace: false\n        folder_first_search: false\n        ignore_root_documents: false\n        supporting_type_mutability: false\n        license: accept\n      monitor_enabled: false\n      logging_enabled: false\n      collectd_enable_plugin_write_graphite: false\n      datavolume:\n        existing_pvc_for_cmis_cfgstore: \n          name: "cmis-cfgstore"\n          size: 1Gi\n        existing_pvc_for_cmis_logstore: \n          name: "cmis-logstore"\n          size: 1Gi\n      probe:\n        startup:\n          initial_delay_seconds: 90\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        readiness:\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        liveness:\n          period_seconds: 10\n          timeout_seconds: 5\n          failure_threshold: 6\n      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.\n      image_pull_secrets:\n        name: "ibm-entitlement-key"\n\n    graphql:\n      arch:\n        amd64: "3 - Most preferred"\n      replica_count: 2\n      image:\n        ## The default repository is the IBM Entitled Registry.\n        repository: cp.icr.io/cp/cp4a/fncm/graphql\n        tag: ga-5510-p8cgql-if001\n        pull_policy: IfNotPresent\n      log:\n        format: json\n      resources:\n        requests:\n          cpu: "500m"\n          memory: "512Mi"\n          ephemeral_storage: "1Gi"\n        limits:\n          cpu: "1"\n          memory: "1536Mi"\n          ephemeral_storage: "1Gi"\n      auto_scaling:\n        enabled: false\n        max_replicas: "<Required>"\n        min_replicas: "<Required>"\n        target_cpu_utilization_percentage: "<Required>"\n      graphql_production_setting:\n        time_zone: Etc/UTC\n        jvm_initial_heap_percentage: 40\n        jvm_max_heap_percentage: 66\n        jvm_customize_options:\n        license_model: FNCM.PVUNonProd\n        license: accept\n        enable_graph_iql: false\n      monitor_enabled: false\n      logging_enabled: false\n      collectd_enable_plugin_write_graphite: false\n      datavolume:\n        existing_pvc_for_graphql_cfgstore: \n          name: "graphql-cfgstore"\n          size: 1Gi\n        existing_pvc_for_graphql_logstore: \n          name: "graphql-logstore"\n          size: 1Gi\n      probe:\n        startup:\n          initial_delay_seconds: 120\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        readiness:\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        liveness:\n          period_seconds: 10\n          timeout_seconds: 5\n          failure_threshold: 6\n      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.\n      image_pull_secrets:\n        name: "ibm-entitlement-key"\n\n    es:\n      arch:\n        amd64: "3 - Most preferred"\n      replica_count: 2\n      image:\n        ## The default repository is the IBM Entitled Registry.\n        repository: cp.icr.io/cp/cp4a/fncm/extshare\n        tag: ga-3013-es-la102\n        pull_policy: IfNotPresent\n      resources:\n        requests:\n          cpu: "500m"\n          memory: "512Mi"\n          ephemeral_storage: "1Gi"\n        limits:\n          cpu: "1"\n          memory: "1536Mi"\n          ephemeral_storage: "1Gi"\n      auto_scaling:\n        enabled: false\n        max_replicas: "<Required>"\n        min_replicas: "<Required>"\n        target_cpu_utilization_percentage: "<Required>"\n      es_production_setting:\n        time_zone: Etc/UTC\n        jvm_initial_heap_percentage: 40\n        jvm_max_heap_percentage: 66\n        jvm_customize_options:\n        license_model: FNCM.PVUNonProd\n        license: accept\n        allowed_origins:\n      monitor_enabled: false\n      logging_enabled: false\n      collectd_enable_plugin_write_graphite: false\n      datavolume:\n        existing_pvc_for_es_cfgstore: \n          name: "es-cfgstore"\n          size: 1Gi\n        existing_pvc_for_es_logstore: \n          name: "es-logstore"\n          size: 1Gi\n      probe:\n        startup:\n          initial_delay_seconds: 180\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        readiness:\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        liveness:\n          period_seconds: 10\n          timeout_seconds: 5\n          failure_threshold: 6\n      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.\n      image_pull_secrets:\n        name: "ibm-entitlement-key"\n\n    tm:\n      arch:\n        amd64: "3 - Most preferred"\n      replica_count: 2\n      image:\n        ## The default repository is the IBM Entitled Registry.\n        repository: cp.icr.io/cp/cp4a/fncm/taskmgr\n        tag: ga-3013-tm-la102\n        pull_policy: IfNotPresent\n      resources:\n        requests:\n          cpu: "500m"\n          memory: "512Mi"\n          ephemeral_storage: "1Gi"\n        limits:\n          cpu: "1"\n          memory: "1536Mi"\n          ephemeral_storage: "1Gi"\n      auto_scaling:\n        enabled: false\n        max_replicas: "<Required>"\n        min_replicas: "<Required>"\n        target_cpu_utilization_percentage: "<Required>"\n      tm_production_setting:\n        time_zone: Etc/UTC\n        jvm_initial_heap_percentage: 40\n        jvm_max_heap_percentage: 66\n        jvm_customize_options: "-Dcom.ibm.ecm.task.StartUpListener.defaultLogLevel=FINE"\n        license: accept\n        security_roles_to_group_mapping:\n           task_admins:\n             groups: [taskAdmins]\n             users: []\n           task_users:\n             groups: [taskUsers]\n             users: []\n           task_auditors:\n             groups: [taskAuditors]\n             users: []\n      monitor_enabled: false\n      logging_enabled: false\n      collectd_enable_plugin_write_graphite: false\n      datavolume:\n        existing_pvc_for_tm_cfgstore: \n          name: "tm-cfgstore"\n          size: 1Gi\n        existing_pvc_for_tm_logstore: \n          name: "tm-logstore"\n          size: 1Gi\n        existing_pvc_for_tm_pluginstore: \n          name: "tm-pluginstore"\n          size: 1Gi\n      probe:\n        startup:\n          initial_delay_seconds: 120\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        readiness:\n          period_seconds: 10\n          timeout_seconds: 10\n          failure_threshold: 6\n        liveness:\n          period_seconds: 10\n          timeout_seconds: 5\n          failure_threshold: 6\n      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.\n      image_pull_secrets:\n        name: "ibm-entitlement-key"\n\n  navigator_configuration:\n    ban_secret_name: ibm-ban-secret\n    arch:\n      amd64: "3 - Most preferred"\n    replica_count: 2\n    image:\n      ## The default repository is the IBM Entitled Registry\n      repository: cp.icr.io/cp/cp4a/ban/navigator\n      tag: ga-3013-icn-la102\n      pull_policy: IfNotPresent\n    log:\n      format: json\n    resources:\n      requests:\n        cpu: "500m"\n        memory: "512Mi"\n        ephemeral_storage: "1Gi"\n      limits:\n        cpu: "1"\n        memory: "3072Mi"\n        ephemeral_storage: "2.5Gi"\n      auto_scaling:\n        enabled: false\n        max_replicas: "<Required>"\n        min_replicas: "<Required>"\n        target_cpu_utilization_percentage: "<Required>"\n    node_affinity:\n      custom_node_selector_match_expression: [ ]\n    custom_annotations: { }\n    custom_labels: { }\n    java_mail:\n      host: "fncm-exchange1.ibm.com"\n      port: "25"\n      sender: "MailAdmin@fncmexchange.com"\n      ssl_enabled: false\n    disable_fips: true\n    icn_production_setting:\n      timezone: Etc/UTC\n      gdfontpath: "/opt/ibm/java/jre/lib/fonts"\n      jvm_initial_heap_percentage: 40\n      jvm_max_heap_percentage: 66\n      jvm_customize_options:\n      icn_jndids_name: ECMClientDS\n      icn_schema: ICNDB\n      icn_table_space: ICNDB\n      allow_remote_plugins_via_http: false\n    monitor_enabled: false\n    logging_enabled: false\n    datavolume:\n      existing_pvc_for_icn_cfgstore: \n        name: "icn-cfgstore"\n        size: 1Gi\n      existing_pvc_for_icn_logstore: \n        name: "icn-logstore"\n        size: 1Gi\n      existing_pvc_for_icn_pluginstore: \n        name: "icn-pluginstore"\n        size: 1Gi\n      existing_pvc_for_icnvw_cachestore: \n        name: "icn-vw-cachestore"\n        size: 1Gi\n      existing_pvc_for_icnvw_logstore: \n        name: "icn-vw-logstore"\n        size: 1Gi\n      existing_pvc_for_icn_aspera: \n        name: "icn-asperastore" \n        size: 1Gi\n    probe:\n      startup:\n        initial_delay_seconds: 120\n        period_seconds: 10\n        timeout_seconds: 10\n        failure_threshold: 6\n      readiness:\n        period_seconds: 10\n        timeout_seconds: 10\n        failure_threshold: 6\n      liveness:\n        period_seconds: 10\n        timeout_seconds: 5\n        failure_threshold: 6\n    ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.\n    image_pull_secrets:\n      name: "ibm-entitlement-key"\n\n    ## Optional entry only if you have the open_id_connect_providers enabled.\n    ## if not specified it will be set to false.\n    ## Enabling this will give the user the option to sign-in using the LDAP.\n    #enable_ldap: true\n')))}m.isMDXComponent=!0}}]);